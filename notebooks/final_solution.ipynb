{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas -q\n",
        "%pip install torch -q\n",
        "%pip install transformers -q\n",
        "%pip install ipywidgets -q\n",
        "%pip install --user -U nltk -q\n",
        "%pip install datasets sacrebleu -q\n",
        "%pip install evaluate -q\n",
        "%pip install accelerate -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_SJ70RMtLdj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /workspaces/PMLDL_Assignment1/notebooks\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "/workspaces/PMLDL_Assignment1/src/data\n",
            "/workspaces/PMLDL_Assignment1/src/visualization\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd() if 'current_dir' not in locals() else current_dir\n",
        "print(f'Current directory: {current_dir}')\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%cd {current_dir}/../src/data\n",
        "from make_dataset import load_dataframe\n",
        "from dataframe_preprocessing import preprocess\n",
        "from text_preprocessing import simple_row_preprocessing\n",
        "from analysis.analyze import get_toxic_words\n",
        "\n",
        "%cd {current_dir}/../src/visualization\n",
        "from visualize import visualize\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ds_T_nImtJbt"
      },
      "outputs": [],
      "source": [
        "df = load_dataframe()\n",
        "\n",
        "df_processed = preprocess(df) # add more columns, switch ref and trn\n",
        "df_processed = df_processed.apply(simple_row_preprocessing, axis=1) # preprocess text in simple way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: train on a subset of dataset: take reference toxic with score > 75% (~0.94), difference > 0.5, translation toxic < 25% (0.04) or something\n",
        "+ should compute metric of initial dataset, the preprocessed and the filtered as a baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of datapoints: 449100\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "      <th>similarity</th>\n",
              "      <th>lenght_diff</th>\n",
              "      <th>ref_tox</th>\n",
              "      <th>trn_tox</th>\n",
              "      <th>tox_diff</th>\n",
              "      <th>ref_length</th>\n",
              "      <th>trn_length</th>\n",
              "      <th>length_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>110388</th>\n",
              "      <td>they ll come scared shitless i ll get the trut...</td>\n",
              "      <td>i m sure they ll come scared shitless i m gonn...</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.923222</td>\n",
              "      <td>0.377313</td>\n",
              "      <td>0.546</td>\n",
              "      <td>65</td>\n",
              "      <td>79</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546382</th>\n",
              "      <td>the chef is eager for a rabbit or a wimp thari...</td>\n",
              "      <td>cook has a hankering to cook some rabbit or gr...</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.907365</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.907</td>\n",
              "      <td>56</td>\n",
              "      <td>70</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358156</th>\n",
              "      <td>most people want sex and meat so it means that...</td>\n",
              "      <td>most people are squirrely about sex and flesh ...</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.992469</td>\n",
              "      <td>0.011296</td>\n",
              "      <td>0.981</td>\n",
              "      <td>73</td>\n",
              "      <td>87</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37266</th>\n",
              "      <td>now now give it back to me you silly little goose</td>\n",
              "      <td>now give it back to my little goose</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.999074</td>\n",
              "      <td>0.001795</td>\n",
              "      <td>0.997</td>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190651</th>\n",
              "      <td>who knows if this is some fool s errand or the...</td>\n",
              "      <td>who knows if this is a crazy message or do we all</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.909461</td>\n",
              "      <td>0.000904</td>\n",
              "      <td>0.909</td>\n",
              "      <td>65</td>\n",
              "      <td>51</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                reference  \\\n",
              "110388  they ll come scared shitless i ll get the trut...   \n",
              "546382  the chef is eager for a rabbit or a wimp thari...   \n",
              "358156  most people want sex and meat so it means that...   \n",
              "37266   now now give it back to me you silly little goose   \n",
              "190651  who knows if this is some fool s errand or the...   \n",
              "\n",
              "                                              translation  similarity  \\\n",
              "110388  i m sure they ll come scared shitless i m gonn...        0.93   \n",
              "546382  cook has a hankering to cook some rabbit or gr...        0.62   \n",
              "358156  most people are squirrely about sex and flesh ...        0.81   \n",
              "37266                 now give it back to my little goose        0.79   \n",
              "190651  who knows if this is a crazy message or do we all        0.70   \n",
              "\n",
              "        lenght_diff   ref_tox   trn_tox  tox_diff  ref_length  trn_length  \\\n",
              "110388         0.18  0.923222  0.377313     0.546          65          79   \n",
              "546382         0.20  0.907365  0.000080     0.907          56          70   \n",
              "358156         0.16  0.992469  0.011296     0.981          73          87   \n",
              "37266          0.27  0.999074  0.001795     0.997          51          37   \n",
              "190651         0.21  0.909461  0.000904     0.909          65          51   \n",
              "\n",
              "        length_difference  \n",
              "110388                 14  \n",
              "546382                 14  \n",
              "358156                 14  \n",
              "37266                  14  \n",
              "190651                 14  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter. Take only the most valuable. Drastically reduce the size of a dataset\n",
        "df_for_training = df_processed[df_processed['length_difference'] < 15]\n",
        "df_for_training = df_for_training[df_for_training['trn_length'] < 70]\n",
        "df_for_training = df_for_training[df_for_training['trn_tox'] < 0.002]\n",
        "df_for_training = df_for_training[df_for_training['ref_tox'] > 0.95]\n",
        "df_for_training = df_for_training[df_for_training['similarity'] > 0.8]\n",
        "print('number of datapoints:',len(df_for_training))\n",
        "df_for_training.sort_values(by='length_difference', ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n",
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "prefix = \"paraphrase from toxic to neutral: \"\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"output_dir\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True,\n",
        "    # fp16=True,\n",
        "    report_to='tensorboard',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[\"reference\"]]\n",
        "    targets = examples[\"translation\"]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
        "    return model_inputs\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WSdBcRztM4G"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vF8d7LFItN2m"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6d25a09ca8b44278f2f676a636da7e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/400000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50dbb4dee132431893837ed30d1eaefa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/49100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = Dataset.from_pandas(df_for_training[['reference', 'translation']].iloc[:400000]).map(preprocess_function, batched=True)\n",
        "val_dataset = Dataset.from_pandas(df_for_training[['reference', 'translation']].iloc[400000:]).map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"saved_moodel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = prefix + \"you can t talk to these old ass ladies like that\"\n",
        "checkp = 'saved_moodel'\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkp)\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
        "\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiUa833xtOJv"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdRd42nOtPRA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
