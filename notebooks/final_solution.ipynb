{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas -q\n",
        "%pip install torch -q\n",
        "%pip install transformers -q\n",
        "%pip install ipywidgets -q\n",
        "%pip install --user -U nltk -q\n",
        "%pip install datasets sacrebleu -q\n",
        "%pip install evaluate -q\n",
        "%pip install accelerate -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter and split on train and validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!python ../src/models/filter_split_train_val.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test simple models - hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test baseline model to compare all other metrics with"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-23 18:28:14.450036: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-23 18:28:14.450093: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-23 18:28:14.450153: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-23 18:28:14.457112: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/workspaces/PMLDL_Assignment1/notebooks/../src/models/metric/compute_metric.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  dataframe = pd.read_csv(dataframe_file, sep=separator)\n",
            "\n",
            "(Translation, Prediction)\n",
            "(\"you didn't know that Estelle stole your fish from the garbage.\", \"You didn't know that Estelle had stolen some fish from your bin.\")\n",
            "(\"you'd be sucked out of your life!\", \"It'il suck the life out of you!\")\n",
            "(\"I really can't take this.\", \"I can't fuckin' take that, bruv.\")\n",
            "(\"they said I was a hero, but I didn't care.\", \"They called me a fucking hero. The truth is I didn't care anymore.\")\n",
            "(\"I didn't fuck him.\", 'I did not screw him.')\n",
            "That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Computed sacrebleu: {'score': 22.8917754786834, 'counts': [3908067, 1973217, 1078158, 580476], 'totals': [7372539, 6794762, 6217078, 5642973], 'precisions': [53.0084276258152, 29.040266605364543, 17.341876682261347, 10.286705252709874], 'bp': 1.0, 'sys_len': 7372539, 'ref_len': 6899727}\n",
            "Score: 22.89%\n"
          ]
        }
      ],
      "source": [
        "!python ../src/models/metric/compute_metric.py --dataframe_file=../data/raw/filtered.tsv --predictions_column=reference --separator='\\t'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-23 18:32:29.174844: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-23 18:32:29.174898: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-23 18:32:29.174960: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-23 18:32:29.181973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/workspaces/PMLDL_Assignment1/notebooks/../src/models/metric/compute_metric.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
            "  dataframe = pd.read_csv(dataframe_file, sep=separator)\n",
            "\n",
            "(Translation, Prediction)\n",
            "('you didn t know that estelle had stolen some fish from your bin', 'you didn t know that estelle stole your fish from the garbage')\n",
            "('you d be sucked out of your life', 'it il suck the life out of you')\n",
            "('i really can t take this', 'i can t fuckin take that bruv')\n",
            "('they said i was a hero but i didn t care', 'they called me a fucking hero the truth is i didn t care anymore')\n",
            "('i did not screw him', 'i didn t fuck him')\n",
            "Computed sacrebleu: {'score': 25.21085920534741, 'counts': [3456677, 1774830, 956137, 515615], 'totals': [6130128, 5552368, 4978722, 4418196], 'precisions': [56.388333163679455, 31.96528039928189, 19.204466527755518, 11.670260893812769], 'bp': 1.0, 'sys_len': 6130128, 'ref_len': 5983432}\n",
            "Score: 25.21%\n"
          ]
        }
      ],
      "source": [
        "!python ../src/models/metric/compute_metric.py --dataframe_file=../data/interim/preprocessed.csv --predictions_column=reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-23 18:35:01.055900: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-23 18:35:01.055947: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-23 18:35:01.055991: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-23 18:35:01.063060: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/workspaces/PMLDL_Assignment1/notebooks/../src/models/metric/compute_metric.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
            "  dataframe = pd.read_csv(dataframe_file, sep=separator)\n",
            "\n",
            "(Translation, Prediction)\n",
            "('mike used to say the worst thing about shooting a gun was the recoil', 'mike used to say the worst thing to do was shoot the gun')\n",
            "('why didn t you listen to me', 'why the fuck didn t you listen to me')\n",
            "('almost as easy as discarding your wife and child', 'as easy as getting rid of a woman and child')\n",
            "('yeah but his mother was a stray', 'yeah but his mother was a didicoy whore')\n",
            "('no you re holding me in the interrogation room', 'no you re holding me in a damn interrogation chamber')\n",
            "Computed sacrebleu: {'score': 37.53686104883171, 'counts': [152831, 87987, 50865, 27780], 'totals': [226178, 194665, 163438, 133002], 'precisions': [67.57111655421836, 45.19918834921532, 31.12189331734358, 20.886903956331484], 'bp': 1.0, 'sys_len': 226178, 'ref_len': 205767}\n",
            "Score: 37.54%\n"
          ]
        }
      ],
      "source": [
        "!python ../src/models/metric/compute_metric.py --dataframe_file=../data/interim/train.csv --predictions_column=reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-23 18:36:32.138354: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-23 18:36:32.138399: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-23 18:36:32.138458: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-23 18:36:32.148301: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/workspaces/PMLDL_Assignment1/notebooks/../src/models/metric/compute_metric.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
            "  dataframe = pd.read_csv(dataframe_file, sep=separator)\n",
            "\n",
            "(Translation, Prediction)\n",
            "('and i deserve it', 'and i d fuckin deserve it')\n",
            "('we finally graduated big dude guy all right', 'fuck dude we finally graduated')\n",
            "('you know who you re messing with', 'you know who you re fuckin with')\n",
            "('police found her car on a th street smashed into a paddock', 'police found her car over on th street smashed to shit')\n",
            "('i ve been hearing it my whole life', 'i ve heard it my whole goddamn life')\n",
            "Computed sacrebleu: {'score': 37.40121452009647, 'counts': [38145, 21936, 12667, 6929], 'totals': [56596, 48717, 40901, 33281], 'precisions': [67.39875609583716, 45.02740316521953, 30.969902936358523, 20.81968690844626], 'bp': 1.0, 'sys_len': 56596, 'ref_len': 51522}\n",
            "Score: 37.40%\n"
          ]
        }
      ],
      "source": [
        "!python ../src/models/metric/compute_metric.py --dataframe_file=../data/interim/val.csv --predictions_column=reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result\n",
        "\n",
        "### As you can see the highest score (37%) is on the filtered data: train or val datasets. So, the final solution will be compared with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test hypothesis 1 model (simple removal of swearing words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit the train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate on validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The result of simple solution is quite good. It is 10% more than of baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final model - T5 fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_SJ70RMtLdj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /workspaces/PMLDL_Assignment1/notebooks\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "/workspaces/PMLDL_Assignment1/src/data\n",
            "/workspaces/PMLDL_Assignment1/src/visualization\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd() if 'current_dir' not in locals() else current_dir\n",
        "print(f'Current directory: {current_dir}')\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%cd {current_dir}/../src/data\n",
        "from make_dataset import load_dataframe\n",
        "from dataframe_preprocessing import preprocess\n",
        "from text_preprocessing import simple_row_preprocessing\n",
        "from analysis.analyze import get_toxic_words\n",
        "\n",
        "%cd {current_dir}/../src/visualization\n",
        "from visualize import visualize\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ds_T_nImtJbt"
      },
      "outputs": [],
      "source": [
        "df = load_dataframe()\n",
        "\n",
        "df_processed = preprocess(df) # add more columns, switch ref and trn\n",
        "df_processed = df_processed.apply(simple_row_preprocessing, axis=1) # preprocess text in simple way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: train on a subset of dataset: take reference toxic with score > 75% (~0.94), difference > 0.5, translation toxic < 25% (0.04) or something\n",
        "+ should compute metric of initial dataset, the preprocessed and the filtered as a baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of datapoints: 449100\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "      <th>similarity</th>\n",
              "      <th>lenght_diff</th>\n",
              "      <th>ref_tox</th>\n",
              "      <th>trn_tox</th>\n",
              "      <th>tox_diff</th>\n",
              "      <th>ref_length</th>\n",
              "      <th>trn_length</th>\n",
              "      <th>length_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>110388</th>\n",
              "      <td>they ll come scared shitless i ll get the trut...</td>\n",
              "      <td>i m sure they ll come scared shitless i m gonn...</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.923222</td>\n",
              "      <td>0.377313</td>\n",
              "      <td>0.546</td>\n",
              "      <td>65</td>\n",
              "      <td>79</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546382</th>\n",
              "      <td>the chef is eager for a rabbit or a wimp thari...</td>\n",
              "      <td>cook has a hankering to cook some rabbit or gr...</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.907365</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.907</td>\n",
              "      <td>56</td>\n",
              "      <td>70</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358156</th>\n",
              "      <td>most people want sex and meat so it means that...</td>\n",
              "      <td>most people are squirrely about sex and flesh ...</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.992469</td>\n",
              "      <td>0.011296</td>\n",
              "      <td>0.981</td>\n",
              "      <td>73</td>\n",
              "      <td>87</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37266</th>\n",
              "      <td>now now give it back to me you silly little goose</td>\n",
              "      <td>now give it back to my little goose</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.999074</td>\n",
              "      <td>0.001795</td>\n",
              "      <td>0.997</td>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190651</th>\n",
              "      <td>who knows if this is some fool s errand or the...</td>\n",
              "      <td>who knows if this is a crazy message or do we all</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.909461</td>\n",
              "      <td>0.000904</td>\n",
              "      <td>0.909</td>\n",
              "      <td>65</td>\n",
              "      <td>51</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                reference  \\\n",
              "110388  they ll come scared shitless i ll get the trut...   \n",
              "546382  the chef is eager for a rabbit or a wimp thari...   \n",
              "358156  most people want sex and meat so it means that...   \n",
              "37266   now now give it back to me you silly little goose   \n",
              "190651  who knows if this is some fool s errand or the...   \n",
              "\n",
              "                                              translation  similarity  \\\n",
              "110388  i m sure they ll come scared shitless i m gonn...        0.93   \n",
              "546382  cook has a hankering to cook some rabbit or gr...        0.62   \n",
              "358156  most people are squirrely about sex and flesh ...        0.81   \n",
              "37266                 now give it back to my little goose        0.79   \n",
              "190651  who knows if this is a crazy message or do we all        0.70   \n",
              "\n",
              "        lenght_diff   ref_tox   trn_tox  tox_diff  ref_length  trn_length  \\\n",
              "110388         0.18  0.923222  0.377313     0.546          65          79   \n",
              "546382         0.20  0.907365  0.000080     0.907          56          70   \n",
              "358156         0.16  0.992469  0.011296     0.981          73          87   \n",
              "37266          0.27  0.999074  0.001795     0.997          51          37   \n",
              "190651         0.21  0.909461  0.000904     0.909          65          51   \n",
              "\n",
              "        length_difference  \n",
              "110388                 14  \n",
              "546382                 14  \n",
              "358156                 14  \n",
              "37266                  14  \n",
              "190651                 14  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter. Take only the most valuable. Drastically reduce the size of a dataset\n",
        "df_for_training = df_processed[df_processed['length_difference'] < 15]\n",
        "df_for_training = df_for_training[df_for_training['trn_length'] < 70]\n",
        "df_for_training = df_for_training[df_for_training['trn_tox'] < 0.002]\n",
        "df_for_training = df_for_training[df_for_training['ref_tox'] > 0.95]\n",
        "df_for_training = df_for_training[df_for_training['similarity'] > 0.8]\n",
        "print('number of datapoints:',len(df_for_training))\n",
        "df_for_training.sort_values(by='length_difference', ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n",
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "prefix = \"paraphrase from toxic to neutral: \"\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"output_dir\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True,\n",
        "    # fp16=True,\n",
        "    report_to='tensorboard',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[\"reference\"]]\n",
        "    targets = examples[\"translation\"]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
        "    return model_inputs\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WSdBcRztM4G"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vF8d7LFItN2m"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6d25a09ca8b44278f2f676a636da7e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/400000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50dbb4dee132431893837ed30d1eaefa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/49100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = Dataset.from_pandas(df_for_training[['reference', 'translation']].iloc[:400000]).map(preprocess_function, batched=True)\n",
        "val_dataset = Dataset.from_pandas(df_for_training[['reference', 'translation']].iloc[400000:]).map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"saved_moodel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = prefix + \"you can t talk to these old ass ladies like that\"\n",
        "checkp = 'saved_moodel'\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkp)\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
        "\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiUa833xtOJv"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdRd42nOtPRA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
