{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas -q\n",
        "%pip install torch -q\n",
        "%pip install transformers -q\n",
        "%pip install ipywidgets -q\n",
        "%pip install --user -U nltk -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re9VDnRXs9Ay"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sFcEgIJs5nr"
      },
      "source": [
        "# Initial data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "zip_file_path = '../data/raw/filtered_paranmt.zip'\n",
        "extracted_dir = '../data/raw/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8D8Fn3NyszUi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to tsv file: ../data/raw/filtered.tsv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "      <th>similarity</th>\n",
              "      <th>lenght_diff</th>\n",
              "      <th>ref_tox</th>\n",
              "      <th>trn_tox</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
              "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
              "      <td>0.785171</td>\n",
              "      <td>0.010309</td>\n",
              "      <td>0.014195</td>\n",
              "      <td>0.981983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Now you're getting nasty.</td>\n",
              "      <td>you're becoming disgusting.</td>\n",
              "      <td>0.749687</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.065473</td>\n",
              "      <td>0.999039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Well, we could spare your life, for one.</td>\n",
              "      <td>well, we can spare your life.</td>\n",
              "      <td>0.919051</td>\n",
              "      <td>0.268293</td>\n",
              "      <td>0.213313</td>\n",
              "      <td>0.985068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
              "      <td>monkey, you have to wake up.</td>\n",
              "      <td>0.664333</td>\n",
              "      <td>0.309524</td>\n",
              "      <td>0.053362</td>\n",
              "      <td>0.994215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I've got orders to put her down.</td>\n",
              "      <td>I have orders to kill her.</td>\n",
              "      <td>0.726639</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.009402</td>\n",
              "      <td>0.999348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                          reference  \\\n",
              "0           0  If Alkar is flooding her with psychic waste, t...   \n",
              "1           1                          Now you're getting nasty.   \n",
              "2           2           Well, we could spare your life, for one.   \n",
              "3           3          Ah! Monkey, you've got to snap out of it.   \n",
              "4           4                   I've got orders to put her down.   \n",
              "\n",
              "                                         translation  similarity  lenght_diff  \\\n",
              "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
              "1                        you're becoming disgusting.    0.749687     0.071429   \n",
              "2                      well, we can spare your life.    0.919051     0.268293   \n",
              "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
              "4                         I have orders to kill her.    0.726639     0.181818   \n",
              "\n",
              "    ref_tox   trn_tox  \n",
              "0  0.014195  0.981983  \n",
              "1  0.065473  0.999039  \n",
              "2  0.213313  0.985068  \n",
              "3  0.053362  0.994215  \n",
              "4  0.009402  0.999348  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tsv_file_name = 'filtered.tsv' \n",
        "\n",
        "# Construct the full path to the TSV file\n",
        "tsv_file_path = os.path.join(extracted_dir, tsv_file_name)\n",
        "print(f\"Path to tsv file: {tsv_file_path}\")\n",
        "\n",
        "# Read the TSV file into a DataFrame\n",
        "df = pd.read_csv(tsv_file_path, delimiter='\\t')\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocesing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing - swap translation and reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def swap_ref_trn(row):\n",
        "    if row['ref_tox'] < row['trn_tox']:\n",
        "        row['reference'], row['translation'] = row['translation'], row['reference']\n",
        "        row['ref_tox'], row['trn_tox'] = row['trn_tox'], row['ref_tox']\n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_stat_columns(df):\n",
        "    df['tox_diff'] = round(df['ref_tox'] - df['trn_tox'], 3)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def round_columns(df):\n",
        "    df['similarity'] = round(df['similarity'], 2)\n",
        "    df['lenght_diff'] = round(df['lenght_diff'], 2)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "    df = df.apply(swap_ref_trn, axis=1)\n",
        "    df = add_stat_columns(df)\n",
        "    df = round_columns(df)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_processed = preprocess(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "      <th>similarity</th>\n",
              "      <th>lenght_diff</th>\n",
              "      <th>ref_tox</th>\n",
              "      <th>trn_tox</th>\n",
              "      <th>tox_diff</th>\n",
              "      <th>length_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
              "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.010309</td>\n",
              "      <td>0.981983</td>\n",
              "      <td>0.014195</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>you're becoming disgusting.</td>\n",
              "      <td>Now you're getting nasty.</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.999039</td>\n",
              "      <td>0.065473</td>\n",
              "      <td>0.934</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>well, we can spare your life.</td>\n",
              "      <td>Well, we could spare your life, for one.</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.268293</td>\n",
              "      <td>0.985068</td>\n",
              "      <td>0.213313</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>monkey, you have to wake up.</td>\n",
              "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.309524</td>\n",
              "      <td>0.994215</td>\n",
              "      <td>0.053362</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I have orders to kill her.</td>\n",
              "      <td>I've got orders to put her down.</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.999348</td>\n",
              "      <td>0.009402</td>\n",
              "      <td>0.990</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577772</th>\n",
              "      <td>577772</td>\n",
              "      <td>you didn't know that Estelle stole your fish f...</td>\n",
              "      <td>You didn't know that Estelle had stolen some f...</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.030769</td>\n",
              "      <td>0.949143</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.949</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577773</th>\n",
              "      <td>577773</td>\n",
              "      <td>It'il suck the life out of you!</td>\n",
              "      <td>you'd be sucked out of your life!</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.996124</td>\n",
              "      <td>0.215794</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577774</th>\n",
              "      <td>577774</td>\n",
              "      <td>I can't fuckin' take that, bruv.</td>\n",
              "      <td>I really can't take this.</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.212121</td>\n",
              "      <td>0.984538</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.984</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577775</th>\n",
              "      <td>577775</td>\n",
              "      <td>They called me a fucking hero. The truth is I ...</td>\n",
              "      <td>they said I was a hero, but I didn't care.</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.358209</td>\n",
              "      <td>0.991945</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577776</th>\n",
              "      <td>577776</td>\n",
              "      <td>I didn't fuck him.</td>\n",
              "      <td>I did not screw him.</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.994174</td>\n",
              "      <td>0.009480</td>\n",
              "      <td>0.985</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>577777 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0                                          reference  \\\n",
              "0                0  if Alkar floods her with her mental waste, it ...   \n",
              "1                1                        you're becoming disgusting.   \n",
              "2                2                      well, we can spare your life.   \n",
              "3                3                       monkey, you have to wake up.   \n",
              "4                4                         I have orders to kill her.   \n",
              "...            ...                                                ...   \n",
              "577772      577772  you didn't know that Estelle stole your fish f...   \n",
              "577773      577773                    It'il suck the life out of you!   \n",
              "577774      577774                   I can't fuckin' take that, bruv.   \n",
              "577775      577775  They called me a fucking hero. The truth is I ...   \n",
              "577776      577776                                 I didn't fuck him.   \n",
              "\n",
              "                                              translation  similarity  \\\n",
              "0       If Alkar is flooding her with psychic waste, t...        0.79   \n",
              "1                               Now you're getting nasty.        0.75   \n",
              "2                Well, we could spare your life, for one.        0.92   \n",
              "3               Ah! Monkey, you've got to snap out of it.        0.66   \n",
              "4                        I've got orders to put her down.        0.73   \n",
              "...                                                   ...         ...   \n",
              "577772  You didn't know that Estelle had stolen some f...        0.87   \n",
              "577773                  you'd be sucked out of your life!        0.72   \n",
              "577774                          I really can't take this.        0.62   \n",
              "577775         they said I was a hero, but I didn't care.        0.68   \n",
              "577776                               I did not screw him.        0.87   \n",
              "\n",
              "        lenght_diff   ref_tox   trn_tox  tox_diff  length_diff  \n",
              "0          0.010309  0.981983  0.014195     0.968         0.01  \n",
              "1          0.071429  0.999039  0.065473     0.934         0.07  \n",
              "2          0.268293  0.985068  0.213313     0.772         0.27  \n",
              "3          0.309524  0.994215  0.053362     0.941         0.31  \n",
              "4          0.181818  0.999348  0.009402     0.990         0.18  \n",
              "...             ...       ...       ...       ...          ...  \n",
              "577772     0.030769  0.949143  0.000121     0.949         0.03  \n",
              "577773     0.058824  0.996124  0.215794     0.780         0.06  \n",
              "577774     0.212121  0.984538  0.000049     0.984         0.21  \n",
              "577775     0.358209  0.991945  0.000124     0.992         0.36  \n",
              "577776     0.095238  0.994174  0.009480     0.985         0.10  \n",
              "\n",
              "[577777 rows x 9 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_processed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Maybe I should assign more weight to the high toxic and good paraphrased data points when training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_processed' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/workspaces/PMLDL_Assignment1/notebooks/exploration_and_preprocessing.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bupgraded-waddle-xqvpg5r4j44h9rj/workspaces/PMLDL_Assignment1/notebooks/exploration_and_preprocessing.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df_processed \u001b[39m=\u001b[39m df_processed\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtox_diff\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlength_diff\u001b[39m\u001b[39m'\u001b[39m], ascending\u001b[39m=\u001b[39m[\u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m])\u001b[39m.\u001b[39miloc[:\u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_processed' is not defined"
          ]
        }
      ],
      "source": [
        "df_processed = df_processed.sort_values(by=['tox_diff', 'similarity', 'length_diff'], ascending=[False, False, True]).iloc[:10].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16TWCktzs-aQ"
      },
      "source": [
        "# Data preprocessing - basic ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Common preprocessing steps:\n",
        "1. Lowercasting\n",
        "1. Removing punctuation\n",
        "1. Removing numbers\n",
        "1. Stemming and lemmatization\n",
        "1. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "MULtJJj4tCcE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "def lower_text(text: str):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_numbers(text: str):\n",
        "    without_numbers = re.sub(r'\\d+', ' ', text)\n",
        "    return without_numbers\n",
        "\n",
        "def remove_punctuation(text: str):\n",
        "    without_punctuation = re.sub(r'[^a-z|\\s]+', ' ', text)\n",
        "    return without_punctuation\n",
        "\n",
        "def remove_multiple_spaces(text: str):\n",
        "    without_doublespace = re.sub('\\s+', ' ', text).strip()\n",
        "    return without_doublespace\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stopwords_set = set(stopwords.words('english'))\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def tokenize_text(text: str):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def remove_stop_words(tokenized_text: list[str]):\n",
        "    return [\n",
        "        w for w in tokenized_text\n",
        "        if w not in stopwords_set\n",
        "    ]\n",
        "\n",
        "def stem_words(tokenized_text: list[str]):\n",
        "    return [\n",
        "        ps.stem(w)\n",
        "        for w in tokenized_text\n",
        "    ]\n",
        "\n",
        "def clean_data(sentence):\n",
        "    _lowered = lower_text(sentence)\n",
        "    _without_numbers = remove_numbers(_lowered)\n",
        "    _without_punct = remove_punctuation(_without_numbers)\n",
        "    _single_spaced = remove_multiple_spaces(_without_punct)\n",
        "    _tokenized = tokenize_text(_single_spaced)\n",
        "    _without_sw = remove_stop_words(_tokenized)\n",
        "    _stemmed = stem_words(_without_sw)\n",
        "    return _stemmed\n",
        "    \n",
        "def clean_dataframe(df, filename='cleaned.csv', dir='../data/interim/', override=False):\n",
        "    file = os.path.join(dir, filename)\n",
        "\n",
        "    # Check cache\n",
        "    if (os.path.exists(file) and not override):\n",
        "        return pd.read_csv(file)\n",
        "    \n",
        "    df['reference'] = df['reference'].apply(lambda s: clean_data(s))\n",
        "    df['translation'] = df['translation'].apply(lambda s: clean_data(s))\n",
        "\n",
        "    # Cache version\n",
        "    df.to_csv(file, index=False)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "      <th>similarity</th>\n",
              "      <th>lenght_diff</th>\n",
              "      <th>ref_tox</th>\n",
              "      <th>trn_tox</th>\n",
              "      <th>tox_diff</th>\n",
              "      <th>length_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[alkar, flood, mental, wast, would, explain, h...</td>\n",
              "      <td>[alkar, flood, psychic, wast, explain, high, l...</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.010309</td>\n",
              "      <td>0.981983</td>\n",
              "      <td>0.014195</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[becom, disgust]</td>\n",
              "      <td>[get, nasti]</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.999039</td>\n",
              "      <td>0.065473</td>\n",
              "      <td>0.934</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[well, spare, life]</td>\n",
              "      <td>[well, could, spare, life, one]</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.268293</td>\n",
              "      <td>0.985068</td>\n",
              "      <td>0.213313</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[monkey, wake]</td>\n",
              "      <td>[ah, monkey, got, snap]</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.309524</td>\n",
              "      <td>0.994215</td>\n",
              "      <td>0.053362</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[order, kill]</td>\n",
              "      <td>[got, order, put]</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.999348</td>\n",
              "      <td>0.009402</td>\n",
              "      <td>0.990</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                          reference  \\\n",
              "0           0  [alkar, flood, mental, wast, would, explain, h...   \n",
              "1           1                                   [becom, disgust]   \n",
              "2           2                                [well, spare, life]   \n",
              "3           3                                     [monkey, wake]   \n",
              "4           4                                      [order, kill]   \n",
              "\n",
              "                                         translation  similarity  lenght_diff  \\\n",
              "0  [alkar, flood, psychic, wast, explain, high, l...        0.79     0.010309   \n",
              "1                                       [get, nasti]        0.75     0.071429   \n",
              "2                    [well, could, spare, life, one]        0.92     0.268293   \n",
              "3                            [ah, monkey, got, snap]        0.66     0.309524   \n",
              "4                                  [got, order, put]        0.73     0.181818   \n",
              "\n",
              "    ref_tox   trn_tox  tox_diff  length_diff  \n",
              "0  0.981983  0.014195     0.968         0.01  \n",
              "1  0.999039  0.065473     0.934         0.07  \n",
              "2  0.985068  0.213313     0.772         0.27  \n",
              "3  0.994215  0.053362     0.941         0.31  \n",
              "4  0.999348  0.009402     0.990         0.18  "
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cleaned = clean_dataframe(df_processed, override=True)\n",
        "df_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check what words were removed after paraphrasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import ast\n",
        "counter = Counter()\n",
        "\n",
        "for i in df_cleaned.iterrows():\n",
        "    ref = i[1]['reference']\n",
        "    trn = i[1]['translation']\n",
        "\n",
        "    if not isinstance(ref, list):    \n",
        "        ref = ast.literal_eval(ref)\n",
        "\n",
        "    if not isinstance(ref, list):    \n",
        "        trn = ast.literal_eval(trn)\n",
        "    \n",
        "    \n",
        "    for r in ref:\n",
        "        if (r not in trn): \n",
        "            counter[r] += 1\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'counter' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/workspaces/PMLDL_Assignment1/notebooks/exploration_and_preprocessing.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bupgraded-waddle-xqvpg5r4j44h9rj/workspaces/PMLDL_Assignment1/notebooks/exploration_and_preprocessing.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39mfuck\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m counter, \u001b[39m'\u001b[39m\u001b[39midiot\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m counter\n",
            "\u001b[0;31mNameError\u001b[0m: name 'counter' is not defined"
          ]
        }
      ],
      "source": [
        "'fuck' in counter, 'idiot' in counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('kill', tensor(0.2149))\n",
            "('gon', tensor(0.2484))\n",
            "('na', tensor(0.2793))\n",
            "('ass', tensor(0.2120))\n",
            "('go', tensor(0.2452))\n",
            "('shit', tensor(0.5674))\n",
            "('like', tensor(0.2144))\n",
            "('fuck', tensor(1.))\n",
            "('got', tensor(0.1766))\n",
            "('damn', tensor(0.4085))\n",
            "('get', tensor(0.2468))\n",
            "('hell', tensor(0.2663))\n",
            "('stupid', tensor(0.1612))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as nn\n",
        "# counter.keys(), \n",
        "inp = torch.tensor(list(counter.values()), dtype=torch.float)\n",
        "probs = inp / inp.max()\n",
        "\n",
        "percent = 0.15\n",
        "\n",
        "z = zip(counter.keys(), probs)\n",
        "for i, j in enumerate(z):\n",
        "    \n",
        "    if ( j[1] > percent): print(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evalution\n",
        "## Methods\n",
        "1. BLUE score\n",
        "1. Perplexity\n",
        "1. BERT assesment\n",
        "1. Other nlp assesment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-09-30 12:37:02.770132: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-09-30 12:37:02.770185: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-09-30 12:37:02.775373: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-09-30 12:37:03.817451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model_name = \"gpt2\"  # You can use other model names like \"gpt2-medium\" or \"gpt2-large\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'input_ids': tensor([[ 1639,   821,   884,   281, 22324, 21551,     0, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])},\n",
              " {'input_ids': tensor([[   40, 12546,   351,   345,    13, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])})"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_texts = [\n",
        "    {\"toxic\": \"You're such an idiot!\", \"rephrased\": \"I disagree with you.\"},\n",
        "    {\"toxic\": \"This is terrible!\", \"rephrased\": \"This is not ideal.\"},\n",
        "    # Add more pairs as needed\n",
        "]\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "def tok(sent):\n",
        "    return tokenizer(sent, padding='max_length', truncation=True, max_length=10, return_tensors=\"pt\")\n",
        "\n",
        "tok(train_texts[0]['toxic']), tok(train_texts[0]['rephrased'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the synonim to the word fuck? Tell only one word as our output.\n",
            "\n",
            "The synonym for fuck is a word that is used to describe a sexual act. It is often used in the context of a relationship, but\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is the synonim to the word fuck? Tell only one word as our output\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text\n",
        "output = model.generate(input_ids, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50)\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True, tempreture=0)\n",
        "\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Methods\n",
        "1. Select toxic words or parts and then paraphrase them\n",
        "1. Translate into French as the most similar to English and then back to English\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "identify toxic words and replace them with non-toxic synonyms.\n",
        "since Such markers (i) carry most of stylistic information of a sentence(i.e.their presence is a strong indicator of this class),(ii) have synonyms which are free from this stylistic information.\n",
        "need to somehow identify what words are toxic in the current dataset"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
